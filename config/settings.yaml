# Kenza AI Configuration
# ========================

# Preferred Provider: 'groq' (fast, reliable) or 'gemini' (multimodal vision)
preferred_provider: "groq"

# API Keys - load from .env file via environment variables (recommended)
# Set GEMINI_API_KEY and GROQ_API_KEY in .env, or fill in below as fallback
api_keys:
  gemini: ""  # Get from https://aistudio.google.com/
  groq: ""    # Get from https://console.groq.com/

# Model Configuration
models:
  gemini: "gemini-2.0-flash"
  groq: "llama-3.3-70b-versatile"  # Fast & capable
  preferred_provider: "groq"  # Primary for text chat
  # Llama model for offline mode (download from HuggingFace)
  llama_path: "models/llama-3.2-3b-instruct.Q4_K_M.gguf"
  llama_context: 2048
  llama_threads: 4

# Voice Settings (Edge-TTS)
voice:
  # Current voice preset (persisted)
  current: "aria"
  
  # Voice presets - say "change voice to {name}"
  presets:
    kenza: "en-US-AriaNeural"      # Default Friendly
    glitch: "en-US-ChristopherNeural" # Robotic/Calm
    kawaii: "en-US-AnaNeural"      # Anime/Child
    titan: "en-US-EricNeural"      # Deep/Authoritative
    jarvis: "en-GB-RyanNeural"     # British Butler
  
  wake_word: "kenza"

# Audio Settings
audio:
  energy_threshold: 200     # Lowered to match RPi mic sensitivity
  listen_timeout: 10        # Seconds to wait for speech
  phrase_time_limit: 8      # Max phrase length in seconds

# GPIO Settings (Raspberry Pi LEDs)
gpio:
  enabled: true
  led_listening: 24   # Green LED - BCM pin
  led_thinking: 25    # Red LED - BCM pin

# Sleep Commands (phrases that put Kenza back to sleep)
sleep_commands:
  - "that's all"
  - "go to sleep"
  - "stop"
  - "goodbye"
  - "bye"
  - "thank you that's all"

# Kenza Personality
personality:
  name: "Kenza"
  creator: "Amruth"
  description: "A sentient robotic companion with vision and voice"
  acknowledgments:
    - "Ah, I understand now"
    - "Yup, I can surely do that"
    - "Of course!"
    - "Got it"
    - "Sure thing"
    - "Right away"
    - "On it"
  thinking_phrases:
    - "Let me think about that..."
    - "Hmm, one moment..."
    - "Let me check..."

# Vision Settings
vision:
  enabled: true
  context_timeout: 60  # seconds to keep image context for follow-ups

# Connectivity (internet check for cloud vs offline switching)
connectivity:
  check_interval: 30   # seconds between internet checks (ping 8.8.8.8)

# Speech-to-Text Settings
stt:
  offline_model: "base.en"   # faster-whisper model when offline (tiny.en / base.en / small.en)
  language: "en"

# Text-to-Speech Settings
tts:
  prefer_online: true         # Edge-TTS (neural) when internet available; espeak when offline

# AI / LLM Settings
# Offline LLM fallback chain: Groq (cloud) → Gemini (cloud) → Ollama → LlamaGGUF
ai:
  # Active offline model served by Ollama (http://localhost:11434)
  # Pull models with: ollama pull <model>
  # Options: gemma3:270m | ministral-3:3b-instruct-2512-q4_K_M | phi3:mini | tinyllama:1.1b | mistral:7b
  ollama_model: "gemma3:270m"
  ollama_url: "http://localhost:11434"
